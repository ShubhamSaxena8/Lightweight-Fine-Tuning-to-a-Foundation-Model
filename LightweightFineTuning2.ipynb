{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {
    "id": "f35354cd"
   },
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {
    "id": "560fb3ff"
   },
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LoRa\n",
    "* Model: distilbert-base-uncased\n",
    "* Evaluation approach: Comparing Accuracy\n",
    "* Fine-tuning dataset: sms_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {
    "id": "de8d76bb"
   },
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f551c63a",
    "outputId": "6bc0d225-d3b9-4560-ce18-6e60bca6017c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/student/.local/lib/python3.10/site-packages (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/student/.local/lib/python3.10/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/student/.local/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.29.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/student/.local/lib/python3.10/site-packages (4.38.0.dev0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/student/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "! pip install -q \"datasets==2.15.0\"\n",
    "! pip install -U accelerate\n",
    "! pip install -U transformers\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4935cb4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4935cb4d",
    "outputId": "30db0fa0-8143-4c54-8c93-77274f8fcd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 60\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sms_spam dataset\n",
    "# See: https://huggingface.co/datasets/sms_spam\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
    "dataset = load_dataset(\"sms_spam\", split=\"train\").select(range(100)).train_test_split(\n",
    "    test_size=0.4, shuffle=True, seed=42\n",
    ")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f28c4a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "f100ba36096f4324931e2923dcce0209",
      "224cf5829de743e0afefe0b025c0571c",
      "9a35368632174b0783f2d0c7715494d8",
      "642f53edb6ff41c49ecec2bde7dc2682",
      "a9e0e21033d24270a209e9f27c00d942",
      "7476897849bb48d99ce3c2606d9e9af4",
      "f45e686be89b45028c2eab3b32d87a3e",
      "590acb989323416ba04081e28d666d5b",
      "2a3f160de0994a5c81ff7e07a9aa290b",
      "8caced8bdacc4e9f97dd5b1c13b5e440",
      "0689faa9f76a4407baaa564dee5a95e6"
     ]
    },
    "id": "f28c4a78",
    "outputId": "6d1c3cb6-7d53-4f11-99b3-dbeb4e9f19da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 60/60 [00:00<00:00, 4142.32 examples/s]\n",
      "Map: 100%|██████████| 40/40 [00:00<00:00, 3856.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 60\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "019b9f55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "019b9f55",
    "outputId": "b7c89a6f-068d-4fc9-bc70-084f3a1ac2c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "\n",
    "# Unfreeze all the model parameters.\n",
    "# Hint: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in model.parameters():\n",
    "    param.required_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5176b07f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "5176b07f",
    "outputId": "325e424d-91f6-4ef9-8880-5dc9aa62838c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662624</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.7166260480880737, metrics={'train_runtime': 2.4775, 'train_samples_per_second': 24.218, 'train_steps_per_second': 1.615, 'total_flos': 967632951120.0, 'train_loss': 0.7166260480880737, 'epoch': 1.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./original_spam_not_spam\",\n",
    "        # Set the learning rate\n",
    "        learning_rate = 2e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size = 16,\n",
    "        per_device_eval_batch_size = 16,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c629b290",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "c629b290",
    "outputId": "4761f559-c969-4541-9b97-cfa0caaa1c50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {
    "id": "4d52a229"
   },
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5775fadf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5775fadf",
    "outputId": "f07d5c67-ce55-4a86-c545-3f9ae2116d77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 67,842,052 || trainable%: 1.307510568813573\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Set the PEFT configuration\n",
    "config = LoraConfig(\n",
    "    r=8,  # Number of attention heads to replace\n",
    "    lora_alpha=32,  # Scaling factor for the Lora layers\n",
    "    #target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"k_lin\", \"out_lin\"],\n",
    "    inference_mode=False,\n",
    "    lora_dropout=0.1,  # Dropout rate for the Lora layers\n",
    "    task_type=\"SEQ_CLS\",  # Type of task (e.g., CAUSAL_LM, SEQ2SEQ)\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "\n",
    "# Create the PEFT model\n",
    "peft_model = get_peft_model(model, config)\n",
    "\n",
    "# Print the trainable parameters\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "894046c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "894046c0",
    "outputId": "560c072c-b993-4e98-dbc0-a5270ae3a642"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559011</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.6328960657119751, metrics={'train_runtime': 0.95, 'train_samples_per_second': 63.157, 'train_steps_per_second': 4.21, 'total_flos': 987538173600.0, 'train_loss': 0.6328960657119751, 'epoch': 1.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "peft_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./peft_spam_not_spam\",\n",
    "        # Set the learning rate\n",
    "        learning_rate = 5e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size = 16,\n",
    "        per_device_eval_batch_size = 16,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the PEFT model\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4d4c908",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "c4d4c908",
    "outputId": "767bee2f-14d9-4e00-9a9a-728d95f588c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5590114593505859,\n",
       " 'eval_accuracy': 0.925,\n",
       " 'eval_runtime': 0.0847,\n",
       " 'eval_samples_per_second': 472.112,\n",
       " 'eval_steps_per_second': 35.408,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b47abf88",
   "metadata": {
    "id": "b47abf88"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the PEFT model weights\n",
    "peft_model.save_pretrained(\"./peft_model_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa7fe003",
   "metadata": {
    "id": "fa7fe003"
   },
   "outputs": [],
   "source": [
    "peft_trainer.save_model(\"./peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {
    "id": "615b12c6"
   },
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6SrmXNCj15x9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SrmXNCj15x9",
    "outputId": "32c67ddb-4d23-471a-dcb7-01f24ed39ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='distilbert-base-uncased', revision=None, task_type='SEQ_CLS', inference_mode=True, r=8, target_modules={'v_lin', 'out_lin', 'k_lin', 'q_lin'}, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={})\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "# load pretrained model with peft\n",
    "peft_model_path = \"peft_model_weights\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_path) # load config\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cL6tLR1BQGmW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cL6tLR1BQGmW",
    "outputId": "19dfa50c-7c43-4aa6-e581-e207afee6472"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(peft_model_path,  num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "jEr9T670KM2l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "jEr9T670KM2l",
    "outputId": "57101f22-b8ca-4eba-c244-b6f768b9f993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.775\n",
      "PEFT Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the PEFT model\n",
    "peft_trainer.evaluate()\n",
    "\n",
    "# Compare the results to the results from prior to fine-tuning\n",
    "original_accuracy = trainer.state.log_history[-1][\"eval_accuracy\"]\n",
    "peft_accuracy = peft_trainer.state.log_history[-1][\"eval_accuracy\"]\n",
    "print(f\"Original Accuracy: {original_accuracy}\")\n",
    "print(f\"PEFT Accuracy: {peft_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1a440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0689faa9f76a4407baaa564dee5a95e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "224cf5829de743e0afefe0b025c0571c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7476897849bb48d99ce3c2606d9e9af4",
      "placeholder": "​",
      "style": "IPY_MODEL_f45e686be89b45028c2eab3b32d87a3e",
      "value": "Map: 100%"
     }
    },
    "2a3f160de0994a5c81ff7e07a9aa290b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "590acb989323416ba04081e28d666d5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "642f53edb6ff41c49ecec2bde7dc2682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8caced8bdacc4e9f97dd5b1c13b5e440",
      "placeholder": "​",
      "style": "IPY_MODEL_0689faa9f76a4407baaa564dee5a95e6",
      "value": " 60/60 [00:00&lt;00:00, 860.40 examples/s]"
     }
    },
    "7476897849bb48d99ce3c2606d9e9af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8caced8bdacc4e9f97dd5b1c13b5e440": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a35368632174b0783f2d0c7715494d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_590acb989323416ba04081e28d666d5b",
      "max": 60,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a3f160de0994a5c81ff7e07a9aa290b",
      "value": 60
     }
    },
    "a9e0e21033d24270a209e9f27c00d942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f100ba36096f4324931e2923dcce0209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_224cf5829de743e0afefe0b025c0571c",
       "IPY_MODEL_9a35368632174b0783f2d0c7715494d8",
       "IPY_MODEL_642f53edb6ff41c49ecec2bde7dc2682"
      ],
      "layout": "IPY_MODEL_a9e0e21033d24270a209e9f27c00d942"
     }
    },
    "f45e686be89b45028c2eab3b32d87a3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
